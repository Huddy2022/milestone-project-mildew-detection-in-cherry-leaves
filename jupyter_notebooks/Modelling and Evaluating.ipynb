{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "0aStgWSO0E0E"
            },
            "source": [
                "# **Modeling and Evaluation Notebook**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "1eLEkw5O0ECa"
            },
            "source": [
                "## Objectives\n",
                "\n",
                "* Answer business requirement 2:\n",
                "  * The client is interested in prediciting if a cherry leaf is healthy or contains powdery mildew.\n",
                "\n",
                "## Inputs\n",
                "\n",
                "* inputs/cherry-leaves_dataset/cherry-leaves/train\n",
                "* inputs/cherry-leaves_dataset/cherry-leaves/test\n",
                "* inputs/cherry-leaves_dataset/cherry-leaves/validation\n",
                "* image shape embeddings (pickle file)\n",
                "\n",
                "## Outputs\n",
                "\n",
                "* Images distribution plot in train, validation, and test set\n",
                "  * Label distribution in a bar chart\n",
                "  * Dataset distribution in a pie chart\n",
                "* Image augmentation\n",
                "* Class indices to change prediction inference in labels\n",
                "* TensorFlow convolutional network machine learning model\n",
                "* Hyperparameter optimisation pipeline\n",
                "* Model trained on best hyperparameters as generated by Keras Tuner\n",
                "* Save trained model\n",
                "* Learning curve plot for model performance\n",
                "* Model evaluation on pickle file\n",
                "* Create a confusion matrix report\n",
                "* Calculate classification report (Model A)\n",
                "* Calculate classification report focusing on precision, recall, f1-score and accuracy (Model B)\n",
                "* Prediction on the random image file\n",
                "\n",
                "## Comments/Insights/Conclusions\n",
                "\n",
                "* The same data was plotted in different versions to accomodate possible client's requests of further data understanding, and saved in outputs V1 - V9.\n",
                "* The CNN was built to seek the maximum accuracy while minimizing loss and training time, various models/hyperparameters were chosen.\n",
                "* The CNN was kept as small as possible withouth compromising accuracy and avoiding overfitting or underfitting.\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "9uWZXH9LwoQg"
            },
            "source": [
                "---"
            ]
        },
        {
            "source": [
                "## Import packages"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from matplotlib.image import imread"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "cqP-UeN-z3i2"
            },
            "source": [
                "# Change working directory"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "aOGIGS-uz3i2"
            },
            "source": [
                "We need to change the working directory from its current folder to its parent folder\n",
                "* We access the current directory with os.getcwd()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "wZfF_j-Bz3i4",
                "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
            },
            "outputs": [],
            "source": [
                "import os\n",
                "current_dir = os.getcwd()\n",
                "current_dir"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "9MWW8E7lz3i7"
            },
            "source": [
                "We want to make the parent of the current directory the new current directory\n",
                "* os.path.dirname() gets the parent directory\n",
                "* os.chir() defines the new current directory"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "TwHsQRWjz3i9",
                "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c",
                "tags": []
            },
            "outputs": [],
            "source": [
                "os.chdir(os.path.dirname(current_dir))\n",
                "print(\"You set a new current directory\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "M_xPk_Ijz3i-"
            },
            "source": [
                "Confirm the new current directory"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "vz3S-_kjz3jA",
                "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
            },
            "outputs": [],
            "source": [
                "current_dir = os.getcwd()\n",
                "current_dir"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "-mavJ8DibrcQ"
            },
            "source": [
                "## Set input directories"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Set train, validation and test paths"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "my_data_dir = 'inputs/cherry-leaves_dataset/cherry-leaves'\n",
                "train_path = my_data_dir + '/train'\n",
                "val_path = my_data_dir + '/validation'\n",
                "test_path = my_data_dir + '/test'"
            ]
        },
        {
            "source": [
                "## Set output directory"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "version = 'v2'\n",
                "file_path = f'outputs/{version}'\n",
                "\n",
                "if 'outputs' in os.listdir(current_dir) and version in os.listdir(current_dir + '/outputs'):\n",
                "  print('Old version is already available create a new version.')\n",
                "  pass\n",
                "else:\n",
                "  os.makedirs(name=file_path)"
            ]
        },
        {
            "source": [
                "## Set labels"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "labels = os.listdir(train_path)\n",
                "\n",
                "print(\n",
                "    f\"Project Labels: {labels}\"\n",
                "    )"
            ]
        },
        {
            "source": [
                "## Set image shape"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import joblib\n",
                "version = 'v2'\n",
                "image_shape = joblib.load(filename=f\"outputs/{version}/image_shape.pkl\")\n",
                "image_shape"
            ]
        },
        {
            "source": [
                "---"
            ],
            "cell_type": "markdown",
            "metadata": {
                "id": "ZY3l0-AxO93d"
            }
        },
        {
            "source": [
                "# Number of images in train, test and validation data"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": [
                "Count number of images per label & set"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "df_freq = pd.DataFrame([]) \n",
                "for folder in ['train', 'validation', 'test']:\n",
                "  for label in labels:\n",
                "    df_freq = df_freq.append(\n",
                "        pd.Series(data={'Set': folder,\n",
                "                        'Label': label,\n",
                "                        'Frequency':int(len(os.listdir(my_data_dir + '/' + folder + '/' + label)))}\n",
                "                  ),\n",
                "                  ignore_index=True\n",
                "        )\n",
                "    print(f\"* {folder} - {label}: {len(os.listdir(my_data_dir+'/'+ folder + '/' + label))} images\")\n",
                "\n",
                "print(df_freq)"
            ]
        },
        {
            "source": [
                "## Bar chart for label distribution"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sns.set_style(\"whitegrid\")\n",
                "plt.figure(figsize=(8,5))\n",
                "ax = sns.barplot(data=df_freq, x='Set', y='Frequency', hue='Label')\n",
                "\n",
                "for p in ax.patches:\n",
                "    height = p.get_height()\n",
                "    ax.text(p.get_x() + p.get_width() / 2, height, f'{height}', ha='center', va='bottom')\n",
                "\n",
                "plt.legend(loc='upper right')\n",
                "plt.title('Cherry leaves Label distribution')\n",
                "plt.savefig(f'{file_path}/labels_distribution.png', bbox_inches='tight', dpi=150)\n",
                "plt.show()"
            ]
        },
        {
            "source": [
                "## Pie chart for dataset distribution"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(8,5))\n",
                "set_labels = df_freq['Set'].unique()\n",
                "colors = sns.color_palette('pastel')[:len(set_labels)]\n",
                "explode = [0.1] * len(set_labels)\n",
                "\n",
                "set_frequencies = []\n",
                "for set_label in set_labels:\n",
                "    set_frequencies.append(df_freq[df_freq['Set'] == set_label]['Frequency'].sum())\n",
                "\n",
                "plt.pie(set_frequencies, labels=set_labels, colors=colors, explode=explode, autopct='%.0f%%')\n",
                "plt.title('Cherry leaves dataset distribution')\n",
                "plt.savefig(f'{file_path}/sets_distribution_pie.png',\n",
                "            bbox_inches='tight', dpi=150)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "uFQo3ycuO-v6"
            },
            "source": [
                "----"
            ]
        },
        {
            "source": [
                "# Image data augmentation"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                " Our dataset only shows a limited number of images, we need to train the model by augmenting the images to better improve the ML performance"
            ]
        },
        {
            "source": [
                "## Import ImageDataGenerator form Tensorflow"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
            ]
        },
        {
            "source": [
                "## Intiatize ImageDataGenerator"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "augmented_image_data = ImageDataGenerator(rotation_range=20,\n",
                "                                   width_shift_range=0.10, \n",
                "                                   height_shift_range=0.10,\n",
                "                                   shear_range=0.1,\n",
                "                                   zoom_range=0.1,\n",
                "                                   horizontal_flip=True,\n",
                "                                   vertical_flip=True,\n",
                "                                   fill_mode='nearest',\n",
                "                                   rescale=1./255\n",
                "                              )"
            ]
        },
        {
            "source": [
                "## Augment training image dataset & set batch size"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "batch_size = 20\n",
                "train_set = augmented_image_data.flow_from_directory(train_path,\n",
                "                                              target_size=image_shape[:2],\n",
                "                                              color_mode='rgb',\n",
                "                                              batch_size=batch_size,\n",
                "                                              class_mode='binary',\n",
                "                                              shuffle=True\n",
                "                                              )\n",
                "\n",
                "train_set.class_indices"
            ]
        },
        {
            "source": [
                "## Augment validation image dataset"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "validation_set = ImageDataGenerator(rescale=1./255).flow_from_directory(val_path,\n",
                "                                                          target_size=image_shape[:2],\n",
                "                                                          color_mode='rgb',\n",
                "                                                          batch_size=batch_size,\n",
                "                                                          class_mode='binary',\n",
                "                                                          shuffle=False\n",
                "                                                          )\n",
                "\n",
                "validation_set.class_indices"
            ]
        },
        {
            "source": [
                "## Augment test image dataset"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "test_set = ImageDataGenerator(rescale=1./255).flow_from_directory(test_path,\n",
                "                                                    target_size=image_shape[:2],\n",
                "                                                    color_mode='rgb',\n",
                "                                                    batch_size=batch_size,\n",
                "                                                    class_mode='binary',\n",
                "                                                    shuffle=False\n",
                "                                                    )\n",
                "\n",
                "test_set.class_indices"
            ]
        },
        {
            "source": [
                "## Plot augmented training image"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "\n",
                "for _ in range(3):\n",
                "    plt.figure(figsize=(3, 3))\n",
                "    img, label = train_set.next()\n",
                "    print(img.shape)\n",
                "    plt.imshow(img[0])\n",
                "    plt.show()"
            ]
        },
        {
            "source": [
                "## Plot augmented validation image"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "for _ in range(3):\n",
                "    plt.figure(figsize=(3, 3))\n",
                "    img, label = validation_set.next()\n",
                "    print(img.shape)\n",
                "    plt.imshow(img[0])\n",
                "    plt.show()"
            ]
        },
        {
            "source": [
                "## Plot augmented test image"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "for _ in range(3):\n",
                "    plt.figure(figsize=(3, 3))\n",
                "    img, label = test_set.next()\n",
                "    print(img.shape)\n",
                "    plt.imshow(img[0])\n",
                "    plt.show()"
            ]
        },
        {
            "source": [
                "## Save class_indices"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "joblib.dump(value=train_set.class_indices ,\n",
                "            filename=f\"{file_path}/class_indices.pkl\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "source": [
                "# Model creation"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": [
                "## Install and import the Keras Tuner for hyperparameter optimisation"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "!pip install keras-tuner"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import tensorflow as tf\n",
                "from tensorflow import keras\n",
                "import keras_tuner as kt"
            ]
        },
        {
            "source": [
                "## Import model packages"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from tensorflow.keras.models import Sequential\n",
                "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D, BatchNormalization\n",
                "from tensorflow.keras import regularizers"
            ]
        },
        {
            "source": [
                "## Contsruct function to create hypermodel for hypertuning"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_tf_model(hp):\n",
                "    model = Sequential()\n",
                "\n",
                "    model.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=image_shape, activation='relu',))\n",
                "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
                "\n",
                "    model.add(Conv2D(filters=64, kernel_size=(3,3), input_shape=image_shape, activation='relu',))\n",
                "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
                "\n",
                "    model.add(Conv2D(filters=64, kernel_size=(3,3), input_shape=image_shape, activation='relu',))\n",
                "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
                "\n",
                "    model.add(Flatten())\n",
                "    hp_units = hp.Int('units', min_value=128, max_value=256, step=32)\n",
                "    model.add(Dense(units=hp_units, activation = 'relu'))\n",
                "\n",
                "    model.add(Dropout(0.5))    \n",
                "    model.add(Dense(1, activation='sigmoid'))\n",
                "    \n",
                "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-3, 1e-4])\n",
                "\n",
                "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
                "                loss='binary_crossentropy',\n",
                "                metrics=['accuracy'])\n",
                "    \n",
                "    return model"
            ]
        },
        {
            "source": [
                "## Hyperparameter Tuning with Hyperband Algorithm"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "tuner = kt.Hyperband(create_tf_model,\n",
                "                     objective='val_accuracy',\n",
                "                     max_epochs=10,\n",
                "                     factor=3,\n",
                "                     directory=file_path,\n",
                "                     project_name='hypertuning')"
            ]
        },
        {
            "source": [
                "## Early Stopping"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from tensorflow.keras.callbacks import EarlyStopping\n",
                "early_stop = EarlyStopping(monitor='val_loss',patience=3)"
            ]
        },
        {
            "source": [
                "## Run the hyperparameter search"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "tuner.search(train_set,\n",
                "          epochs=25,\n",
                "          steps_per_epoch = len(train_set.classes) // batch_size,\n",
                "          validation_data=validation_set,\n",
                "          callbacks=[early_stop],\n",
                "          verbose=1\n",
                "          )\n",
                "\n",
                "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
                "\n",
                "print(f\"\"\"\n",
                "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
                "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
                "is {best_hps.get('learning_rate')}.\n",
                "\"\"\")"
            ]
        },
        {
            "source": [
                "## Create model using defined best hyperparameters"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "model = tuner.hypermodel.build(best_hps)"
            ]
        },
        {
            "source": [
                "## Model Summary"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "model.summary()"
            ]
        },
        {
            "source": [
                "## Re-instantiate the hypermodel with best hyperparameters and retrain it"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "model = tuner.hypermodel.build(best_hps)\n",
                "\n",
                "model.fit(train_set,\n",
                "          epochs=25,\n",
                "          steps_per_epoch = len(train_set.classes) // batch_size,\n",
                "          validation_data=validation_set,\n",
                "          callbacks=[early_stop],\n",
                "          verbose=1\n",
                "          )"
            ]
        },
        {
            "source": [
                "## Save the model"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model.save('outputs/v2/powdery_mildew_detection_model.h5')\n"
            ]
        },
        {
            "source": [
                "----"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": [
                "# Model Performace"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": [
                "----"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": [
                "## Model learning curve"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "losses = pd.DataFrame(model.history.history)\n",
                "\n",
                "sns.set_style(\"whitegrid\")\n",
                "losses[['loss','val_loss']].plot(style='.-')\n",
                "plt.title(\"Loss\")\n",
                "plt.savefig(f'{file_path}/model_training_losses.png', bbox_inches='tight', dpi=150)\n",
                "plt.show()\n",
                "\n",
                "print(\"\\n\")\n",
                "losses[['accuracy','val_accuracy']].plot(style='.-')\n",
                "plt.title(\"Accuracy\")\n",
                "plt.savefig(f'{file_path}/model_training_acc.png', bbox_inches='tight', dpi=150)\n",
                "plt.show()"
            ]
        },
        {
            "source": [
                "# Model Evaluation"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": [
                "## Load saved model"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "from keras.models import load_model\n",
                "model = load_model('outputs/v2/powdery_mildew_detection_model.h5')"
            ]
        },
        {
            "source": [
                "## Evaluate model on test set"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "evaluation = model.evaluate(test_set)\n",
                "print(\"Model accuracy: {:.2f}%\".format(evaluation[1] * 100))\n",
                "print(\"Model Loss: \",evaluation[0])"
            ]
        },
        {
            "source": [
                "## Save evaluation pickle"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "joblib.dump(value=evaluation ,\n",
                "            filename=f\"outputs/v2/evaluation.pkl\")"
            ]
        },
        {
            "source": [
                "## Confusion Matrix"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "from sklearn.metrics import confusion_matrix\n",
                "\n",
                "pred = model.predict(test_set)\n",
                "y_pred = np.concatenate(np.round(pred).astype(int))\n",
                "\n",
                "cm = confusion_matrix(test_set.classes, y_pred)\n",
                "\n",
                "target_names = ['Powdery Mildew', 'Healthy']\n",
                "\n",
                "fig, ax = plt.subplots(figsize=(7, 6))\n",
                "\n",
                "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues',\n",
                "            xticklabels=target_names, yticklabels=target_names,\n",
                "            ax=ax)\n",
                "\n",
                "ax.set_xlabel('Predicted')\n",
                "ax.set_ylabel('Actual')\n",
                "ax.set_title('Confusion Matrix')\n",
                "\n",
                "plt.savefig(f'{file_path}/confusion_matrix.png', bbox_inches='tight', dpi=150)"
            ]
        },
        {
            "source": [
                "## Show wrong class image"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "wrong_indices = np.where((test_set.classes == 1) & (y_pred == 0))[0]\n",
                "\n",
                "wrong_images = [test_set.filenames[i] for i in wrong_indices]\n",
                "\n",
                "print(\"Healthy images wrongly predicted as Powdery Mildew:\")\n",
                "for image in wrong_images:\n",
                "    print(image)"
            ]
        },
        {
            "source": [
                "Display wrong class image from the confusion matrix"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "from PIL import Image\n",
                "\n",
                "image_path = \"inputs/cherry-leaves_dataset/cherry-leaves/test/powdery_mildew/4c756b73-5e7d-40ec-9b36-1866c49f2e43___FREC_Pwd.M 5156_flipLR.JPG\"\n",
                "\n",
                "image = Image.open(image_path)\n",
                "image.show()"
            ]
        },
        {
            "source": [
                "## Classification Report - A"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "from sklearn.metrics import classification_report\n",
                "\n",
                "print('Classification Report:\\n----------------------\\n')\n",
                "print(classification_report(test_set.classes, y_pred, \n",
                "      target_names=target_names))\n"
            ]
        },
        {
            "source": [
                "## Classification Report - B"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "classification_rep = classification_report(test_set.classes, y_pred, target_names=target_names, output_dict=True)\n",
                "\n",
                "print(classification_rep.keys())\n",
                "\n",
                "target_classes = ['accuracy', 'Healthy', 'Powdery Mildew', 'macro avg', 'weighted avg']\n",
                "\n",
                "metric_labels = ['precision', 'recall', 'f1-score']\n",
                "\n",
                "data = np.zeros((len(target_classes), len(metric_labels)))\n",
                "for i, class_label in enumerate(target_classes):\n",
                "    if class_label == 'accuracy':\n",
                "        data[i, :] = round(classification_rep[class_label], 3)\n",
                "    else:\n",
                "        for j, metric_label in enumerate(metric_labels):\n",
                "            data[i, j] = round(classification_rep[class_label][metric_label], 3)\n",
                "\n",
                "plt.figure(figsize=(8, 5))\n",
                "sns.heatmap(data, annot=True, fmt='.3f', cmap=\"Blues\", cbar=True, linewidths=1)\n",
                "plt.xticks(np.arange(len(metric_labels)) + 0.5, metric_labels, rotation=0)\n",
                "plt.yticks(np.arange(len(target_classes)) + 0.5, target_classes, rotation=0)\n",
                "plt.xlabel('Metric')\n",
                "plt.ylabel('Class')\n",
                "plt.title('Classification Report')\n",
                "plt.savefig(f'{file_path}/clf_report.png', bbox_inches='tight', dpi=150)\n",
                "plt.show()"
            ]
        },
        {
            "source": [
                "## Test prediction using a random image"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "import random\n",
                "from tensorflow.keras.preprocessing import image\n",
                "\n",
                "label = labels[0] # select 0 for healthy or 1 for infected\n",
                "\n",
                "image_files = os.listdir(test_path + '/' + label)\n",
                "\n",
                "random_image_file = random.choice(image_files)\n",
                "\n",
                "pil_image = image.load_img(test_path + '/'+ label + '/'+ random_image_file,\n",
                "                          target_size=image_shape, color_mode='rgb')\n",
                "\n",
                "print(f'Image shape: {pil_image.size}, Image mode: {pil_image.mode}')\n",
                "pil_image"
            ]
        },
        {
            "source": [
                "## Convert image to array and prepare for prediction"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "my_image = image.img_to_array(pil_image)\n",
                "my_image = np.expand_dims(my_image, axis=0)/255\n",
                "print(my_image.shape)"
            ]
        },
        {
            "source": [
                "## Predict class probabilities"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "pred_proba = model.predict(my_image)[0,0]\n",
                "\n",
                "target_map = {v: k for k, v in train_set.class_indices.items()}\n",
                "pred_class =  target_map[pred_proba > 0.5]  \n",
                "\n",
                "if pred_class == target_map[0]:\n",
                "    pred_proba = 1 - pred_proba\n",
                "\n",
                "pred_percentage = round(pred_proba * 100, 2)\n",
                "\n",
                "print(f\"Label: {pred_class}\")\n",
                "print(f\"Percentage: {pred_percentage}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "source": [
                "# Conclusion\n",
                "\n",
                "* We analyzed the dataset and visualized the label distribution, providing insights into the dataset's composition.\n",
                "* To improve the model's performance, we applied data augmentation techniques to expand our training dataset.\n",
                "* Using Keras Tuner, we conducted a hyperparameter search to find the best combination of hyperparameters for our model.\n",
                "* The model was trained using the best hyperparameters, and the resulting model was saved for future use.\n",
                "* During the training process, we monitored the loss and accuracy, which allowed us to track the model's learning curve. The final model achieved an accuracy of 99.88%   and a loss of 0.0041 on the test set.\n",
                "* We evaluated the model using a confusion matrix, which provided insights into the model's performance across different classes.\n",
                "* Additionally, we generated two classification reports, which provided detailed metrics such as precision, recall, and F1-score for each class.\n",
                "* Based on the evaluation results, our model demonstrates excellent performance in detecting powdery mildew on cherry leaves, with a high accuracy of 99.88% on the       test set. This meets the performance requirement specified in the business case.\n",
                "\n",
                "By incorporating these evaluation metrics, we can confidently state that our model achieves the desired performance level and can be utilized effectively for the task of powdery mildew detection."
            ],
            "cell_type": "markdown",
            "metadata": {}
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "name": "Data Practitioner Jupyter Notebook.ipynb",
            "provenance": [],
            "toc_visible": true
        },
        "interpreter": {
            "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
        },
        "kernelspec": {
            "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
            "language": "python",
            "name": "python381264bit3812pyenve56f52c545524e45a113ef94cd47a50f"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.12-final"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}